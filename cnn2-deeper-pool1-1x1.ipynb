{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg (0.2.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.14.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (5.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "%xmode Verbose\n",
    "\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.__version__\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN,self).__init__()\n",
    "    \n",
    "    self.conv1_out_ch = 64\n",
    "    self.conv2_out_ch = 128\n",
    "    self.conv3_out_ch = 128\n",
    "    self.conv4_out_ch = 128\n",
    "    self.conv5_out_ch = 128\n",
    "    self.conv6_out_ch = 128\n",
    "    self.conv7_out_ch = 128\n",
    "    self.conv8_out_ch = 128\n",
    "    self.conv9_out_ch = 128\n",
    "    self.conv10_out_ch = 128\n",
    "    self.conv11_out_ch = 128\n",
    "    self.conv12_out_ch = 128\n",
    "\n",
    "    self.dropout_p = 0.5\n",
    "    self.dropout_p_fc = 0.3\n",
    "    \n",
    "    self.conv1 = torch.nn.Conv2d(3, self.conv1_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = torch.nn.BatchNorm2d(self.conv1_out_ch)\n",
    "    self.dropout1 = torch.nn.Dropout(p=self.dropout_p)\n",
    "    \n",
    "    self.conv2 = torch.nn.Conv2d(self.conv1_out_ch, self.conv2_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = torch.nn.BatchNorm2d(self.conv2_out_ch)\n",
    "    self.dropout2 = torch.nn.Dropout(p=self.dropout_p)\n",
    "    self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    self.conv3 = torch.nn.Conv2d(self.conv2_out_ch, self.conv3_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3 = torch.nn.BatchNorm2d(self.conv3_out_ch)\n",
    "    self.dropout3 = torch.nn.Dropout(p=self.dropout_p)\n",
    "    self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    self.conv4 = torch.nn.Conv2d(self.conv3_out_ch, self.conv4_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4 = torch.nn.BatchNorm2d(self.conv4_out_ch)\n",
    "    self.dropout4 = torch.nn.Dropout(p=self.dropout_p)\n",
    "    self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    self.conv5 = torch.nn.Conv2d(self.conv4_out_ch, self.conv5_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn5 = torch.nn.BatchNorm2d(self.conv5_out_ch)\n",
    "    self.dropout5 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv6 = torch.nn.Conv2d(self.conv5_out_ch, self.conv6_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn6 = torch.nn.BatchNorm2d(self.conv6_out_ch)\n",
    "    self.dropout6 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv7 = torch.nn.Conv2d(self.conv6_out_ch, self.conv7_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn7 = torch.nn.BatchNorm2d(self.conv7_out_ch)\n",
    "    self.dropout7 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv8 = torch.nn.Conv2d(self.conv7_out_ch, self.conv8_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn8 = torch.nn.BatchNorm2d(self.conv8_out_ch)\n",
    "    self.dropout8 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv9 = torch.nn.Conv2d(self.conv8_out_ch, self.conv9_out_ch, kernel_size=1, stride=1, padding=0)\n",
    "    self.bn9 = torch.nn.BatchNorm2d(self.conv9_out_ch)\n",
    "    self.dropout9 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv10 = torch.nn.Conv2d(self.conv9_out_ch, self.conv10_out_ch, kernel_size=1, stride=1, padding=0)\n",
    "    self.bn10 = torch.nn.BatchNorm2d(self.conv10_out_ch)\n",
    "    self.dropout10 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv11 = torch.nn.Conv2d(self.conv10_out_ch, self.conv11_out_ch, kernel_size=1, stride=1, padding=0)\n",
    "    self.bn11 = torch.nn.BatchNorm2d(self.conv11_out_ch)\n",
    "    self.dropout11 = torch.nn.Dropout(p=self.dropout_p)\n",
    "    \n",
    "    self.conv12 = torch.nn.Conv2d(self.conv11_out_ch, self.conv12_out_ch, kernel_size=1, stride=1, padding=0)\n",
    "    self.bn12 = torch.nn.BatchNorm2d(self.conv12_out_ch)\n",
    "    self.dropout12 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.fc1 = torch.nn.Linear(self.conv12_out_ch*16*16, 128)\n",
    "    self.dropoutfc1 = torch.nn.Dropout(p=self.dropout_p_fc)\n",
    "    self.fc2 = torch.nn.Linear(128, 10)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    x = F.relu(self.bn1(self.conv1(x)))\n",
    "    x = self.dropout1(x)\n",
    "\n",
    "    x = F.relu(self.bn2(self.conv2(x)))\n",
    "    x = self.dropout2(x)\n",
    "    x = self.pool2(x)\n",
    "    \n",
    "    x = F.relu(self.bn3(self.conv3(x)))\n",
    "    x = self.dropout3(x)\n",
    "    #x = self.pool3(x)\n",
    "    \n",
    "    x = F.relu(self.bn4(self.conv4(x)))\n",
    "    x = self.dropout4(x)\n",
    "    #x = self.pool4(x)        \n",
    "\n",
    "    x = F.relu(self.bn5(self.conv5(x)))\n",
    "    x = self.dropout5(x)\n",
    "    \n",
    "    x = F.relu(self.bn6(self.conv6(x)))\n",
    "    x = self.dropout6(x)\n",
    "\n",
    "    x = F.relu(self.bn7(self.conv7(x)))\n",
    "    x = self.dropout7(x)\n",
    "\n",
    "    x = F.relu(self.bn8(self.conv8(x)))\n",
    "    x = self.dropout8(x)\n",
    "\n",
    "    x = F.relu(self.bn9(self.conv9(x)))\n",
    "    x = self.dropout9(x)\n",
    "\n",
    "    x = F.relu(self.bn10(self.conv10(x)))\n",
    "    x = self.dropout10(x)\n",
    "\n",
    "    x = F.relu(self.bn11(self.conv11(x)))\n",
    "    x = self.dropout11(x)\n",
    "\n",
    "    x = F.relu(self.bn12(self.conv12(x)))\n",
    "    x = self.dropout12(x)\n",
    "\n",
    "    x = x.view(-1, self.conv12_out_ch*4*4)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(loader, model) :\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "\n",
    "  count = 0\n",
    "  accuracy_sum = 0\n",
    "\n",
    "  import sys\n",
    "\n",
    "  with torch.no_grad() :\n",
    "    for x, y in loader :\n",
    "      x = x.float().to(device)\n",
    "      y = y.to(device)\n",
    "      model.eval()\n",
    "      outputs = model.forward(x)\n",
    "\n",
    "      outputs = outputs.cpu().numpy()\n",
    "      y_pred = np.argmax(outputs, axis=1)\n",
    "      y = y.cpu().numpy()\n",
    "\n",
    "      match = (y == y_pred).astype('uint8')\n",
    "      accuracy_sum += np.sum(match) \n",
    "      count += len(match)\n",
    "\n",
    "    accuracy = accuracy_sum / count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./cifardata', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./cifardata', train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "#Training\n",
    "n_training_samples=45000\n",
    "train_sampler=SubsetRandomSampler(np.arange(n_training_samples))\n",
    "\n",
    "#Validation\n",
    "n_val_samples = 5000\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
    "\n",
    "#Test\n",
    "n_test_samples = 10000\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, sampler=test_sampler, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "\n",
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "  print(\"==== HYPERPARAMETERS ====\")\n",
    "  print(\"batch_size=\", batch_size)\n",
    "  print(\"n_epochs=\",n_epochs)\n",
    "  print(\"learning_rate=\",learning_rate)\n",
    "  print(\"=\"*30)\n",
    "  \n",
    "  # Get training data\n",
    "  train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                             batch_size=batch_size,\n",
    "                                             sampler=train_sampler,\n",
    "                                             num_workers=2)\n",
    "  n_batches = len(train_loader)\n",
    "  \n",
    "  # Create loss and optimizer functions\n",
    "  loss = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "  \n",
    "  training_start_time = time.time()\n",
    "  \n",
    "  for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = n_batches\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader,0):\n",
    "      inputs, labels = data\n",
    "      inputs, labels = Variable(inputs), Variable(labels)\n",
    "      inputs = inputs.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      net.train()\n",
    "      outputs = net(inputs)\n",
    "      loss_size = loss(outputs, labels)\n",
    "      loss_size.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      running_loss += loss_size.data\n",
    "      total_train_loss += loss_size.data\n",
    "      \n",
    "      if (i+1)%print_every == 0:\n",
    "        print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took {:.2f}s\".format(\n",
    "              epoch+1, int(100*(i+1)/n_batches), running_loss/print_every, time.time()-start_time))\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "      \n",
    "    # At the end of the epoch, do a pass on the validation set\n",
    "    total_val_loss = 0\n",
    "    for inputs, labels in val_loader:\n",
    "      \n",
    "      inputs, labels = Variable(inputs), Variable(labels)\n",
    "      inputs = inputs.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      net.eval()\n",
    "      val_outputs = net(inputs)\n",
    "      val_loss_size = loss(val_outputs, labels)\n",
    "      total_val_loss += val_loss_size.data\n",
    "      \n",
    "    print(\"Validation loss = {:.2f}\".format(total_val_loss/len(val_loader)))\n",
    "          \n",
    "  print(\"Training finished, took {:.2f}s\".format(time.time()-training_start_time))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ce5bf609503a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mCNN\u001b[0m \u001b[0;34m= SimpleCNN(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.5)\n  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout2): Dropout(p=0.5)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout3): Dropout(p=0.5)\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout4): Dropout(p=0.5)\n  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout5): Dropout(p=0.5)\n  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout6): Dropout(p=0.5)\n  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout7): Dropout(p=0.5)\n  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout8): Dropout(p=0.5)\n  (conv9): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout9): Dropout(p=0.5)\n  (conv10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout10): Dropout(p=0.5)\n  (conv11): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout11): Dropout(p=0.5)\n  (conv12): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout12): Dropout(p=0.5)\n  (fc1): Linear(in_features=32768, out_features=128, bias=True)\n  (dropoutfc1): Dropout(p=0.3)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n)\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mCNN.to\u001b[0m \u001b[0;34m= <bound method Module.to of SimpleCNN(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.5)\n  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout2): Dropout(p=0.5)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout3): Dropout(p=0.5)\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout4): Dropout(p=0.5)\n  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout5): Dropout(p=0.5)\n  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout6): Dropout(p=0.5)\n  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout7): Dropout(p=0.5)\n  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout8): Dropout(p=0.5)\n  (conv9): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout9): Dropout(p=0.5)\n  (conv10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout10): Dropout(p=0.5)\n  (conv11): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout11): Dropout(p=0.5)\n  (conv12): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout12): Dropout(p=0.5)\n  (fc1): Linear(in_features=32768, out_features=128, bias=True)\n  (dropoutfc1): Dropout(p=0.3)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n)>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mdevice\u001b[0m \u001b[0;34m= device(type='cuda')\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self=SimpleCNN(\n  (conv1): Conv2d(3, 64, kernel_size=...ar(in_features=128, out_features=10, bias=True)\n), *args=(device(type='cuda'),), **kwargs={})\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mself._apply\u001b[0m \u001b[0;34m= <bound method Module._apply of SimpleCNN(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.5)\n  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout2): Dropout(p=0.5)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout3): Dropout(p=0.5)\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout4): Dropout(p=0.5)\n  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout5): Dropout(p=0.5)\n  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout6): Dropout(p=0.5)\n  (conv7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout7): Dropout(p=0.5)\n  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout8): Dropout(p=0.5)\n  (conv9): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout9): Dropout(p=0.5)\n  (conv10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout10): Dropout(p=0.5)\n  (conv11): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout11): Dropout(p=0.5)\n  (conv12): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (bn12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout12): Dropout(p=0.5)\n  (fc1): Linear(in_features=32768, out_features=128, bias=True)\n  (dropoutfc1): Dropout(p=0.3)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n)>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mconvert\u001b[0m \u001b[0;34m= <function Module.to.<locals>.convert at 0x7fac5bb4a048>\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self=SimpleCNN(\n  (conv1): Conv2d(3, 64, kernel_size=...ar(in_features=128, out_features=10, bias=True)\n), fn=<function Module.to.<locals>.convert>)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mmodule._apply\u001b[0m \u001b[0;34m= <bound method Module._apply of Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mfn\u001b[0m \u001b[0;34m= <function Module.to.<locals>.convert at 0x7fac5bb4a048>\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self=Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), fn=<function Module.to.<locals>.convert>)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mparam.data\u001b[0m \u001b[0;34m= tensor([[[[ 0.1471,  0.1597, -0.0451],\n          [ 0.1768, -0.0422,  0.0388],\n          [-0.0937,  0.1130,  0.1697]],\n\n         [[-0.1412,  0.1673,  0.0360],\n          [ 0.1422,  0.0261,  0.0928],\n          [-0.0272,  0.1484,  0.0284]],\n\n         [[-0.0898,  0.0491, -0.0887],\n          [-0.0226, -0.0782,  0.1277],\n          [-0.1519, -0.0887, -0.0543]]],\n\n\n        [[[-0.1157,  0.0182, -0.1901],\n          [ 0.1738, -0.1635,  0.1486],\n          [ 0.0320, -0.0625,  0.1189]],\n\n         [[ 0.0300,  0.1555,  0.0210],\n          [-0.0607,  0.0517, -0.0522],\n          [ 0.0810,  0.1718,  0.1112]],\n\n         [[-0.0841,  0.1111,  0.0344],\n          [ 0.0977, -0.1173, -0.1905],\n          [-0.0744, -0.1476,  0.1579]]],\n\n\n        [[[ 0.0554,  0.0797,  0.0609],\n          [-0.0033,  0.1506, -0.1367],\n          [ 0.0121, -0.1314,  0.0593]],\n\n         [[-0.0663,  0.0590, -0.0401],\n          [ 0.1596, -0.1141, -0.1148],\n          [-0.1148,  0.1731,  0.0641]],\n\n         [[ 0.1852, -0.1588, -0.1909],\n          [-0.1506, -0.1295,  0.0780],\n          [ 0.0689,  0.1599, -0.0994]]],\n\n\n        ...,\n\n\n        [[[-0.1489,  0.0282, -0.1691],\n          [-0.0065, -0.0855,  0.0633],\n          [-0.1081,  0.1232, -0.1562]],\n\n         [[ 0.1156, -0.1446,  0.1031],\n          [-0.0810, -0.0004, -0.0351],\n          [ 0.1249,  0.0631, -0.1696]],\n\n         [[ 0.0177, -0.1328,  0.1439],\n          [ 0.0316, -0.0495, -0.0982],\n          [ 0.0666, -0.1153,  0.0913]]],\n\n\n        [[[ 0.1050,  0.1181,  0.0503],\n          [-0.1685,  0.1384, -0.0597],\n          [-0.0569, -0.0207,  0.1407]],\n\n         [[ 0.1480,  0.0297,  0.0918],\n          [-0.1794,  0.0005, -0.1703],\n          [ 0.0655, -0.1371, -0.0686]],\n\n         [[ 0.1345,  0.1839, -0.1155],\n          [-0.1068,  0.0238,  0.0757],\n          [-0.0313, -0.0601, -0.1264]]],\n\n\n        [[[ 0.0822,  0.1886, -0.0932],\n          [ 0.0908,  0.0940,  0.1547],\n          [-0.0219,  0.0061,  0.1414]],\n\n         [[ 0.1217,  0.1901, -0.0552],\n          [ 0.0761,  0.1344, -0.1306],\n          [ 0.0382, -0.0431,  0.1237]],\n\n         [[-0.0864,  0.0135,  0.1151],\n          [-0.1763, -0.1625, -0.0986],\n          [ 0.1234,  0.1290, -0.1314]]]])\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mfn\u001b[0m \u001b[0;34m= <function Module.to.<locals>.convert at 0x7fac5bb4a048>\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t=tensor([[[[ 0.1471,  0.1597, -0.0451],\n         ....0986],\n          [ 0.1234,  0.1290, -0.1314]]]]))\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mt.to\u001b[0m \u001b[0;34m= <built-in method to of Tensor object at 0x7fac3cc35990>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mdevice\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mdtype\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mt.is_floating_point\u001b[0m \u001b[0;34m= <built-in method is_floating_point of Tensor object at 0x7fac3cc35990>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mnon_blocking\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "CNN = SimpleCNN()\n",
    "CNN = CNN.to(device)\n",
    "trainNet(CNN, batch_size=32, n_epochs=100, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = eval_accuracy(test_loader,CNN)\n",
    "print(\"accuracy={:.2f}%\".format(accuracy*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
