{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg (0.2.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.14.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (5.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "%xmode Verbose\n",
    "\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.__version__\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN,self).__init__()\n",
    "    \n",
    "    self.conv1_out_ch = 64\n",
    "    self.conv2_out_ch = 64\n",
    "    self.conv3_out_ch = 64\n",
    "    self.conv4_out_ch = 64\n",
    "    self.conv5_out_ch = 64\n",
    "    self.conv6_out_ch = 64\n",
    "\n",
    "    self.dropout_p = 0.5\n",
    "    \n",
    "    self.conv1 = torch.nn.Conv2d(3, self.conv1_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = torch.nn.BatchNorm2d(self.conv1_out_ch)\n",
    "    self.dropout1 = torch.nn.Dropout(p=self.dropout_p)\n",
    "    self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    \n",
    "    self.conv2 = torch.nn.Conv2d(self.conv1_out_ch, self.conv2_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = torch.nn.BatchNorm2d(self.conv2_out_ch)\n",
    "    self.dropout2 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv3 = torch.nn.Conv2d(self.conv2_out_ch, self.conv3_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3 = torch.nn.BatchNorm2d(self.conv3_out_ch)\n",
    "    self.dropout3 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv4 = torch.nn.Conv2d(self.conv3_out_ch, self.conv4_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4 = torch.nn.BatchNorm2d(self.conv4_out_ch)\n",
    "    self.dropout4 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv5 = torch.nn.Conv2d(self.conv4_out_ch, self.conv5_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn5 = torch.nn.BatchNorm2d(self.conv5_out_ch)\n",
    "    self.dropout5 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.conv6 = torch.nn.Conv2d(self.conv5_out_ch, self.conv6_out_ch, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn6 = torch.nn.BatchNorm2d(self.conv6_out_ch)\n",
    "    self.dropout6 = torch.nn.Dropout(p=self.dropout_p)\n",
    "\n",
    "    self.fc1 = torch.nn.Linear(self.conv6_out_ch*16*16, 64)\n",
    "    self.fc2 = torch.nn.Linear(64, 10)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    x = F.relu(self.bn1(self.conv1(x)))\n",
    "    x = self.dropout1(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = F.relu(self.bn2(self.conv2(x)))\n",
    "    x = self.dropout2(x)\n",
    "    \n",
    "    x = F.relu(self.bn3(self.conv3(x)))\n",
    "    x = self.dropout3(x)\n",
    "    \n",
    "    x = F.relu(self.bn4(self.conv4(x)))\n",
    "    x = self.dropout4(x)\n",
    "    \n",
    "    x = F.relu(self.bn5(self.conv5(x)))\n",
    "    x = self.dropout5(x)\n",
    "    \n",
    "    x = F.relu(self.bn6(self.conv6(x)))\n",
    "    x = self.dropout6(x)\n",
    "    \n",
    "    x = x.view(-1, self.conv6_out_ch*16*16)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(loader, model) :\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "\n",
    "  count = 0\n",
    "  accuracy_sum = 0\n",
    "\n",
    "  import sys\n",
    "\n",
    "  with torch.no_grad() :\n",
    "    for x, y in loader :\n",
    "      x = x.float().to(device)\n",
    "      y = y.to(device)\n",
    "      model.eval()\n",
    "      outputs = model.forward(x)\n",
    "\n",
    "      outputs = outputs.cpu().numpy()\n",
    "      y_pred = np.argmax(outputs, axis=1)\n",
    "      y = y.cpu().numpy()\n",
    "\n",
    "      match = (y == y_pred).astype('uint8')\n",
    "      accuracy_sum += np.sum(match) \n",
    "      count += len(match)\n",
    "\n",
    "    accuracy = accuracy_sum / count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./cifardata', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./cifardata', train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "#Training\n",
    "n_training_samples=45000\n",
    "train_sampler=SubsetRandomSampler(np.arange(n_training_samples))\n",
    "\n",
    "#Validation\n",
    "n_val_samples = 5000\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
    "\n",
    "#Test\n",
    "n_test_samples = 10000\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, sampler=test_sampler, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "\n",
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "  print(\"==== HYPERPARAMETERS ====\")\n",
    "  print(\"batch_size=\", batch_size)\n",
    "  print(\"n_epochs=\",n_epochs)\n",
    "  print(\"learning_rate=\",learning_rate)\n",
    "  print(\"=\"*30)\n",
    "  \n",
    "  # Get training data\n",
    "  train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                             batch_size=batch_size,\n",
    "                                             sampler=train_sampler,\n",
    "                                             num_workers=2)\n",
    "  n_batches = len(train_loader)\n",
    "  \n",
    "  # Create loss and optimizer functions\n",
    "  loss = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "  \n",
    "  training_start_time = time.time()\n",
    "  \n",
    "  for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = n_batches\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader,0):\n",
    "      inputs, labels = data\n",
    "      inputs, labels = Variable(inputs), Variable(labels)\n",
    "      inputs = inputs.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      net.train()\n",
    "      outputs = net(inputs)\n",
    "      loss_size = loss(outputs, labels)\n",
    "      loss_size.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      running_loss += loss_size.data\n",
    "      total_train_loss += loss_size.data\n",
    "      \n",
    "      if (i+1)%print_every == 0:\n",
    "        print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took {:.2f}s\".format(\n",
    "              epoch+1, int(100*(i+1)/n_batches), running_loss/print_every, time.time()-start_time))\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "      \n",
    "    # At the end of the epoch, do a pass on the validation set\n",
    "    total_val_loss = 0\n",
    "    for inputs, labels in val_loader:\n",
    "      \n",
    "      inputs, labels = Variable(inputs), Variable(labels)\n",
    "      inputs = inputs.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      net.eval()\n",
    "      val_outputs = net(inputs)\n",
    "      val_loss_size = loss(val_outputs, labels)\n",
    "      total_val_loss += val_loss_size.data\n",
    "      \n",
    "    print(\"Validation loss = {:.2f}\".format(total_val_loss/len(val_loader)))\n",
    "          \n",
    "  print(\"Training finished, took {:.2f}s\".format(time.time()-training_start_time))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== HYPERPARAMETERS ====\n",
      "batch_size= 32\n",
      "n_epochs= 50\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Epoch 1, 100% \t train_loss: 1.51 took 10.16s\n",
      "Validation loss = 1.56\n",
      "Epoch 2, 100% \t train_loss: 1.20 took 10.20s\n",
      "Validation loss = 1.39\n",
      "Epoch 3, 100% \t train_loss: 1.07 took 10.34s\n",
      "Validation loss = 1.07\n",
      "Epoch 4, 100% \t train_loss: 0.99 took 10.30s\n",
      "Validation loss = 1.34\n",
      "Epoch 5, 100% \t train_loss: 0.93 took 10.24s\n",
      "Validation loss = 1.02\n",
      "Epoch 6, 100% \t train_loss: 0.88 took 14.65s\n",
      "Validation loss = 1.16\n",
      "Epoch 7, 100% \t train_loss: 0.84 took 15.64s\n",
      "Validation loss = 0.99\n",
      "Epoch 8, 100% \t train_loss: 0.80 took 15.81s\n",
      "Validation loss = 1.10\n",
      "Epoch 9, 100% \t train_loss: 0.77 took 16.18s\n",
      "Validation loss = 1.01\n",
      "Epoch 10, 100% \t train_loss: 0.75 took 15.87s\n",
      "Validation loss = 0.97\n",
      "Epoch 11, 100% \t train_loss: 0.73 took 15.91s\n",
      "Validation loss = 1.04\n",
      "Epoch 12, 100% \t train_loss: 0.72 took 15.86s\n",
      "Validation loss = 1.13\n",
      "Epoch 13, 100% \t train_loss: 0.69 took 15.90s\n",
      "Validation loss = 1.06\n",
      "Epoch 14, 100% \t train_loss: 0.68 took 15.86s\n",
      "Validation loss = 0.83\n",
      "Epoch 15, 100% \t train_loss: 0.66 took 16.20s\n",
      "Validation loss = 0.85\n",
      "Epoch 16, 100% \t train_loss: 0.65 took 16.22s\n",
      "Validation loss = 0.86\n",
      "Epoch 17, 100% \t train_loss: 0.64 took 15.88s\n",
      "Validation loss = 0.91\n",
      "Epoch 18, 100% \t train_loss: 0.64 took 15.88s\n",
      "Validation loss = 0.95\n",
      "Epoch 19, 100% \t train_loss: 0.62 took 15.81s\n",
      "Validation loss = 0.99\n",
      "Epoch 20, 100% \t train_loss: 0.61 took 15.89s\n",
      "Validation loss = 1.00\n",
      "Epoch 21, 100% \t train_loss: 0.60 took 15.81s\n",
      "Validation loss = 0.94\n",
      "Epoch 22, 100% \t train_loss: 0.60 took 15.57s\n",
      "Validation loss = 0.78\n",
      "Epoch 23, 100% \t train_loss: 0.59 took 15.82s\n",
      "Validation loss = 0.84\n",
      "Epoch 24, 100% \t train_loss: 0.59 took 15.95s\n",
      "Validation loss = 0.92\n",
      "Epoch 25, 100% \t train_loss: 0.58 took 15.90s\n",
      "Validation loss = 0.90\n",
      "Epoch 26, 100% \t train_loss: 0.57 took 15.86s\n",
      "Validation loss = 0.78\n",
      "Epoch 27, 100% \t train_loss: 0.56 took 16.06s\n",
      "Validation loss = 0.80\n",
      "Epoch 28, 100% \t train_loss: 0.56 took 15.96s\n",
      "Validation loss = 0.97\n",
      "Epoch 29, 100% \t train_loss: 0.56 took 15.81s\n",
      "Validation loss = 0.83\n",
      "Epoch 30, 100% \t train_loss: 0.55 took 15.84s\n",
      "Validation loss = 0.81\n",
      "Epoch 31, 100% \t train_loss: 0.54 took 15.90s\n",
      "Validation loss = 0.75\n",
      "Epoch 32, 100% \t train_loss: 0.54 took 15.97s\n",
      "Validation loss = 0.86\n",
      "Epoch 33, 100% \t train_loss: 0.53 took 16.12s\n",
      "Validation loss = 0.83\n",
      "Epoch 34, 100% \t train_loss: 0.53 took 15.97s\n",
      "Validation loss = 0.89\n",
      "Epoch 35, 100% \t train_loss: 0.53 took 15.97s\n",
      "Validation loss = 0.84\n",
      "Epoch 36, 100% \t train_loss: 0.53 took 15.74s\n",
      "Validation loss = 0.86\n",
      "Epoch 37, 100% \t train_loss: 0.52 took 15.90s\n",
      "Validation loss = 0.88\n",
      "Epoch 38, 100% \t train_loss: 0.51 took 15.92s\n",
      "Validation loss = 0.77\n",
      "Epoch 39, 100% \t train_loss: 0.51 took 16.03s\n",
      "Validation loss = 0.74\n",
      "Epoch 40, 100% \t train_loss: 0.51 took 15.79s\n",
      "Validation loss = 0.85\n",
      "Epoch 41, 100% \t train_loss: 0.50 took 15.81s\n",
      "Validation loss = 0.81\n",
      "Epoch 42, 100% \t train_loss: 0.50 took 15.90s\n",
      "Validation loss = 0.78\n",
      "Epoch 43, 100% \t train_loss: 0.50 took 16.14s\n",
      "Validation loss = 0.81\n",
      "Epoch 44, 100% \t train_loss: 0.50 took 15.58s\n",
      "Validation loss = 0.74\n",
      "Epoch 45, 100% \t train_loss: 0.49 took 16.18s\n",
      "Validation loss = 0.77\n",
      "Epoch 46, 100% \t train_loss: 0.49 took 16.09s\n",
      "Validation loss = 0.77\n",
      "Epoch 47, 100% \t train_loss: 0.49 took 15.74s\n",
      "Validation loss = 0.73\n",
      "Epoch 48, 100% \t train_loss: 0.48 took 15.97s\n",
      "Validation loss = 0.90\n",
      "Epoch 49, 100% \t train_loss: 0.48 took 16.03s\n",
      "Validation loss = 0.89\n",
      "Epoch 50, 100% \t train_loss: 0.47 took 15.79s\n",
      "Validation loss = 0.71\n",
      "Training finished, took 797.52s\n"
     ]
    }
   ],
   "source": [
    "CNN = SimpleCNN()\n",
    "CNN = CNN.to(device)\n",
    "trainNet(CNN, batch_size=32, n_epochs=50, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=76.72%\n"
     ]
    }
   ],
   "source": [
    "accuracy = eval_accuracy(test_loader,CNN)\n",
    "print(\"accuracy={:.2f}%\".format(accuracy*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
